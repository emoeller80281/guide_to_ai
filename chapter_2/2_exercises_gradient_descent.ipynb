{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e1179fa-80d6-4540-b246-419a435b5375",
   "metadata": {},
   "source": [
    "## 2. Gradient Descent Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b11ac6b-4f4e-426c-9a58-bdd913508990",
   "metadata": {},
   "source": [
    "## 2.7 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7f2ebd9-bd9c-40ba-8c7c-7d2868435b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-11 13:38:59.493955: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device='cuda'\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53c9a221-19de-4edc-a0b0-c1a065693658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.3752, device='cuda:0')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"The capital of France is Paris\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "\n",
    "outputs.loss  # This is the average cross-entropy loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df8d712-aaf8-4588-a7c5-28d76d8564f8",
   "metadata": {},
   "source": [
    "Walk through loss computation in a nice table, then remove parts for exercise in book. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1a87f7-d268-432f-a528-f3035ab77b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba22e62-fb54-434a-a129-23614f2288be",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits  # Shape: (1, sequence_length, vocab_size)\n",
    "\n",
    "# Get probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data = []\n",
    "token_ids = inputs[\"input_ids\"][0].cpu().numpy()\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "\n",
    "for i in range(len(token_ids) - 1):\n",
    "    # Input text up to this point\n",
    "    input_so_far = tokenizer.decode(token_ids[:i+1])\n",
    "    \n",
    "    # Get probabilities for next token prediction\n",
    "    next_token_probs = probs[0, i, :]\n",
    "    \n",
    "    # Most likely next token\n",
    "    most_likely_token_id = torch.argmax(next_token_probs).item()\n",
    "    most_likely_token = tokenizer.decode([most_likely_token_id])\n",
    "    most_likely_prob = next_token_probs[most_likely_token_id].item()\n",
    "    \n",
    "    # Correct next token (actual next token in sequence)\n",
    "    correct_token_id = token_ids[i + 1]\n",
    "    correct_token = tokenizer.decode([correct_token_id])\n",
    "    correct_prob = next_token_probs[correct_token_id].item()\n",
    "    \n",
    "    # Negative log likelihood (cross-entropy loss for this token)\n",
    "    nll = -torch.log(next_token_probs[correct_token_id]).item()\n",
    "    \n",
    "    data.append({\n",
    "        'Input Text So Far': input_so_far,\n",
    "        'Most Likely Next Token': most_likely_token,\n",
    "        'Prob of Most Likely': f\"{most_likely_prob:.6f}\",\n",
    "        'Correct Next Token': correct_token,\n",
    "        'Prob of Correct Token': f\"{correct_prob:.6f}\",\n",
    "        'Negative Log Prob': f\"{nll:.6f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('/home/stephen/book_exports/exercise_27.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dde6324-856d-45e5-9762-a127fd642011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Text So Far</th>\n",
       "      <th>Most Likely Next Token</th>\n",
       "      <th>Prob of Most Likely</th>\n",
       "      <th>Correct Next Token</th>\n",
       "      <th>Prob of Correct Token</th>\n",
       "      <th>Negative Log Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|begin_of_text|&gt;</td>\n",
       "      <td>Question</td>\n",
       "      <td>0.301258</td>\n",
       "      <td>The</td>\n",
       "      <td>0.026724</td>\n",
       "      <td>3.622184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|begin_of_text|&gt;The</td>\n",
       "      <td></td>\n",
       "      <td>0.024400</td>\n",
       "      <td>capital</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>8.683147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|begin_of_text|&gt;The capital</td>\n",
       "      <td>of</td>\n",
       "      <td>0.568659</td>\n",
       "      <td>of</td>\n",
       "      <td>0.568659</td>\n",
       "      <td>0.564475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|begin_of_text|&gt;The capital of</td>\n",
       "      <td>the</td>\n",
       "      <td>0.204712</td>\n",
       "      <td>France</td>\n",
       "      <td>0.011272</td>\n",
       "      <td>4.485465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|begin_of_text|&gt;The capital of France</td>\n",
       "      <td>,</td>\n",
       "      <td>0.508131</td>\n",
       "      <td>is</td>\n",
       "      <td>0.141121</td>\n",
       "      <td>1.958141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;|begin_of_text|&gt;The capital of France is</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.391531</td>\n",
       "      <td>Paris</td>\n",
       "      <td>0.391531</td>\n",
       "      <td>0.937692</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Input Text So Far Most Likely Next Token  \\\n",
       "0                          <|begin_of_text|>               Question   \n",
       "1                       <|begin_of_text|>The                          \n",
       "2               <|begin_of_text|>The capital                     of   \n",
       "3            <|begin_of_text|>The capital of                    the   \n",
       "4     <|begin_of_text|>The capital of France                      ,   \n",
       "5  <|begin_of_text|>The capital of France is                  Paris   \n",
       "\n",
       "  Prob of Most Likely Correct Next Token Prob of Correct Token  \\\n",
       "0            0.301258                The              0.026724   \n",
       "1            0.024400            capital              0.000169   \n",
       "2            0.568659                 of              0.568659   \n",
       "3            0.204712             France              0.011272   \n",
       "4            0.508131                 is              0.141121   \n",
       "5            0.391531              Paris              0.391531   \n",
       "\n",
       "  Negative Log Prob  \n",
       "0          3.622184  \n",
       "1          8.683147  \n",
       "2          0.564475  \n",
       "3          4.485465  \n",
       "4          1.958141  \n",
       "5          0.937692  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf83a3a6-1599-494f-bdf7-d6a43d0854b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.3751839999999995)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df['Negative Log Prob']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf1ae11-1df0-4750-8450-05fe022f8843",
   "metadata": {},
   "source": [
    "## 2.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c538c439-c86e-4892-81ba-6ea686dca2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device='cuda'\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f49c9920-254f-408f-928e-4e1ac52b628d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9323, device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"An apple a day keeps the doctor away\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "\n",
    "outputs.loss  # This is the average cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262066a5-f846-4da7-85cf-a5d33d8c9385",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits  # Shape: (1, sequence_length, vocab_size)\n",
    "\n",
    "# Get probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data = []\n",
    "token_ids = inputs[\"input_ids\"][0].cpu().numpy()\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "\n",
    "for i in range(len(token_ids) - 1):\n",
    "    # Input text up to this point\n",
    "    input_so_far = tokenizer.decode(token_ids[:i+1])\n",
    "    \n",
    "    # Get probabilities for next token prediction\n",
    "    next_token_probs = probs[0, i, :]\n",
    "    \n",
    "    # Most likely next token\n",
    "    most_likely_token_id = torch.argmax(next_token_probs).item()\n",
    "    most_likely_token = tokenizer.decode([most_likely_token_id])\n",
    "    most_likely_prob = next_token_probs[most_likely_token_id].item()\n",
    "    \n",
    "    # Correct next token (actual next token in sequence)\n",
    "    correct_token_id = token_ids[i + 1]\n",
    "    correct_token = tokenizer.decode([correct_token_id])\n",
    "    correct_prob = next_token_probs[correct_token_id].item()\n",
    "    \n",
    "    # Negative log likelihood (cross-entropy loss for this token)\n",
    "    nll = -torch.log(next_token_probs[correct_token_id]).item()\n",
    "    \n",
    "    data.append({\n",
    "        'Input Text So Far': input_so_far,\n",
    "        'Most Likely Next Token': most_likely_token,\n",
    "        'Prob of Most Likely': f\"{most_likely_prob:.6f}\",\n",
    "        'Correct Next Token': correct_token,\n",
    "        'Prob of Correct Token': f\"{correct_prob:.6f}\",\n",
    "        'Negative Log Prob': f\"{nll:.6f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('/home/stephen/book_exports/exercise_212.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "544dd00d-a43f-4c44-91f3-cd6a694bb326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Text So Far</th>\n",
       "      <th>Most Likely Next Token</th>\n",
       "      <th>Prob of Most Likely</th>\n",
       "      <th>Correct Next Token</th>\n",
       "      <th>Prob of Correct Token</th>\n",
       "      <th>Negative Log Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|begin_of_text|&gt;</td>\n",
       "      <td>Question</td>\n",
       "      <td>0.301258</td>\n",
       "      <td>An</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>6.381588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An</td>\n",
       "      <td></td>\n",
       "      <td>0.022775</td>\n",
       "      <td>apple</td>\n",
       "      <td>0.000615</td>\n",
       "      <td>7.393639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An apple</td>\n",
       "      <td>a</td>\n",
       "      <td>0.649742</td>\n",
       "      <td>a</td>\n",
       "      <td>0.649742</td>\n",
       "      <td>0.431180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An apple a</td>\n",
       "      <td>day</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>day</td>\n",
       "      <td>0.986583</td>\n",
       "      <td>0.013508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An apple a day</td>\n",
       "      <td>keeps</td>\n",
       "      <td>0.483511</td>\n",
       "      <td>keeps</td>\n",
       "      <td>0.483511</td>\n",
       "      <td>0.726681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An apple a day keeps</td>\n",
       "      <td>the</td>\n",
       "      <td>0.850819</td>\n",
       "      <td>the</td>\n",
       "      <td>0.850819</td>\n",
       "      <td>0.161556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An apple a day keeps the</td>\n",
       "      <td>doctor</td>\n",
       "      <td>0.738021</td>\n",
       "      <td>doctor</td>\n",
       "      <td>0.738021</td>\n",
       "      <td>0.303783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;|begin_of_text|&gt;An apple a day keeps the doctor</td>\n",
       "      <td>away</td>\n",
       "      <td>0.954824</td>\n",
       "      <td>away</td>\n",
       "      <td>0.954824</td>\n",
       "      <td>0.046229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Input Text So Far Most Likely Next Token  \\\n",
       "0                                 <|begin_of_text|>               Question   \n",
       "1                               <|begin_of_text|>An                          \n",
       "2                         <|begin_of_text|>An apple                      a   \n",
       "3                       <|begin_of_text|>An apple a                    day   \n",
       "4                   <|begin_of_text|>An apple a day                  keeps   \n",
       "5             <|begin_of_text|>An apple a day keeps                    the   \n",
       "6         <|begin_of_text|>An apple a day keeps the                 doctor   \n",
       "7  <|begin_of_text|>An apple a day keeps the doctor                   away   \n",
       "\n",
       "  Prob of Most Likely Correct Next Token Prob of Correct Token  \\\n",
       "0            0.301258                 An              0.001692   \n",
       "1            0.022775              apple              0.000615   \n",
       "2            0.649742                  a              0.649742   \n",
       "3            0.986583                day              0.986583   \n",
       "4            0.483511              keeps              0.483511   \n",
       "5            0.850819                the              0.850819   \n",
       "6            0.738021             doctor              0.738021   \n",
       "7            0.954824               away              0.954824   \n",
       "\n",
       "  Negative Log Prob  \n",
       "0          6.381588  \n",
       "1          7.393639  \n",
       "2          0.431180  \n",
       "3          0.013508  \n",
       "4          0.726681  \n",
       "5          0.161556  \n",
       "6          0.303783  \n",
       "7          0.046229  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "389eb73e-e5eb-4a0a-bd09-447d855e1c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(1.9322705)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df['Negative Log Prob']).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b51d8e-6d7f-4430-ae84-0b2cbdbe9a30",
   "metadata": {},
   "source": [
    "## 2.17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fa69f4c-4d1b-4468-841e-cc7fb98cc300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device='cuda'\n",
    "model_id = \"meta-llama/Llama-3.2-1B\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "587a7f88-f98d-4cd8-bb06-24e1f9a4ca4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.5667, device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I've had a perfectly wonderful evening, but this wasn't it\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs, labels=inputs[\"input_ids\"])\n",
    "\n",
    "outputs.loss  # This is the average cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "270cf9cd-ebed-41a1-b008-ad395e8e0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits  # Shape: (1, sequence_length, vocab_size)\n",
    "\n",
    "# Get probabilities\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "\n",
    "# Prepare data for DataFrame\n",
    "data = []\n",
    "token_ids = inputs[\"input_ids\"][0].cpu().numpy()\n",
    "tokens = tokenizer.convert_ids_to_tokens(token_ids)\n",
    "\n",
    "for i in range(len(token_ids) - 1):\n",
    "    # Input text up to this point\n",
    "    input_so_far = tokenizer.decode(token_ids[:i+1])\n",
    "    \n",
    "    # Get probabilities for next token prediction\n",
    "    next_token_probs = probs[0, i, :]\n",
    "    \n",
    "    # Most likely next token\n",
    "    most_likely_token_id = torch.argmax(next_token_probs).item()\n",
    "    most_likely_token = tokenizer.decode([most_likely_token_id])\n",
    "    most_likely_prob = next_token_probs[most_likely_token_id].item()\n",
    "    \n",
    "    # Correct next token (actual next token in sequence)\n",
    "    correct_token_id = token_ids[i + 1]\n",
    "    correct_token = tokenizer.decode([correct_token_id])\n",
    "    correct_prob = next_token_probs[correct_token_id].item()\n",
    "    \n",
    "    # Negative log likelihood (cross-entropy loss for this token)\n",
    "    nll = -torch.log(next_token_probs[correct_token_id]).item()\n",
    "    \n",
    "    data.append({\n",
    "        'Input Text So Far': input_so_far,\n",
    "        'Most Likely Next Token': most_likely_token,\n",
    "        'Prob of Most Likely': f\"{most_likely_prob:.6f}\",\n",
    "        'Correct Next Token': correct_token,\n",
    "        'Prob of Correct Token': f\"{correct_prob:.6f}\",\n",
    "        'Negative Log Prob': f\"{nll:.6f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('/home/stephen/book_exports/exercise_217.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ab8a461-4bd2-45c7-ab03-b466b999dde6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Input Text So Far</th>\n",
       "      <th>Most Likely Next Token</th>\n",
       "      <th>Prob of Most Likely</th>\n",
       "      <th>Correct Next Token</th>\n",
       "      <th>Prob of Correct Token</th>\n",
       "      <th>Negative Log Prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;|begin_of_text|&gt;</td>\n",
       "      <td>Question</td>\n",
       "      <td>0.301258</td>\n",
       "      <td>I</td>\n",
       "      <td>0.006885</td>\n",
       "      <td>4.978397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I</td>\n",
       "      <td>have</td>\n",
       "      <td>0.093446</td>\n",
       "      <td>'ve</td>\n",
       "      <td>0.029747</td>\n",
       "      <td>3.515023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've</td>\n",
       "      <td>been</td>\n",
       "      <td>0.354400</td>\n",
       "      <td>had</td>\n",
       "      <td>0.049489</td>\n",
       "      <td>3.006014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had</td>\n",
       "      <td>a</td>\n",
       "      <td>0.302687</td>\n",
       "      <td>a</td>\n",
       "      <td>0.302687</td>\n",
       "      <td>1.195056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a</td>\n",
       "      <td>few</td>\n",
       "      <td>0.143885</td>\n",
       "      <td>perfectly</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>9.251956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly</td>\n",
       "      <td>good</td>\n",
       "      <td>0.174156</td>\n",
       "      <td>wonderful</td>\n",
       "      <td>0.038335</td>\n",
       "      <td>3.261401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderful</td>\n",
       "      <td>life</td>\n",
       "      <td>0.158798</td>\n",
       "      <td>evening</td>\n",
       "      <td>0.009312</td>\n",
       "      <td>4.676493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderfu...</td>\n",
       "      <td>with</td>\n",
       "      <td>0.164883</td>\n",
       "      <td>,</td>\n",
       "      <td>0.110149</td>\n",
       "      <td>2.205918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderfu...</td>\n",
       "      <td>and</td>\n",
       "      <td>0.103836</td>\n",
       "      <td>but</td>\n",
       "      <td>0.102951</td>\n",
       "      <td>2.273497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderfu...</td>\n",
       "      <td>I</td>\n",
       "      <td>0.327170</td>\n",
       "      <td>this</td>\n",
       "      <td>0.017883</td>\n",
       "      <td>4.023901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderfu...</td>\n",
       "      <td>morning</td>\n",
       "      <td>0.419821</td>\n",
       "      <td>wasn</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>6.416648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderfu...</td>\n",
       "      <td>'t</td>\n",
       "      <td>0.997004</td>\n",
       "      <td>'t</td>\n",
       "      <td>0.997004</td>\n",
       "      <td>0.003001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;|begin_of_text|&gt;I've had a perfectly wonderfu...</td>\n",
       "      <td>it</td>\n",
       "      <td>0.210132</td>\n",
       "      <td>it</td>\n",
       "      <td>0.210132</td>\n",
       "      <td>1.560019</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Input Text So Far Most Likely Next Token  \\\n",
       "0                                   <|begin_of_text|>               Question   \n",
       "1                                  <|begin_of_text|>I                   have   \n",
       "2                               <|begin_of_text|>I've                   been   \n",
       "3                           <|begin_of_text|>I've had                      a   \n",
       "4                         <|begin_of_text|>I've had a                    few   \n",
       "5               <|begin_of_text|>I've had a perfectly                   good   \n",
       "6     <|begin_of_text|>I've had a perfectly wonderful                   life   \n",
       "7   <|begin_of_text|>I've had a perfectly wonderfu...                   with   \n",
       "8   <|begin_of_text|>I've had a perfectly wonderfu...                    and   \n",
       "9   <|begin_of_text|>I've had a perfectly wonderfu...                      I   \n",
       "10  <|begin_of_text|>I've had a perfectly wonderfu...                morning   \n",
       "11  <|begin_of_text|>I've had a perfectly wonderfu...                     't   \n",
       "12  <|begin_of_text|>I've had a perfectly wonderfu...                     it   \n",
       "\n",
       "   Prob of Most Likely Correct Next Token Prob of Correct Token  \\\n",
       "0             0.301258                  I              0.006885   \n",
       "1             0.093446                've              0.029747   \n",
       "2             0.354400                had              0.049489   \n",
       "3             0.302687                  a              0.302687   \n",
       "4             0.143885          perfectly              0.000096   \n",
       "5             0.174156          wonderful              0.038335   \n",
       "6             0.158798            evening              0.009312   \n",
       "7             0.164883                  ,              0.110149   \n",
       "8             0.103836                but              0.102951   \n",
       "9             0.327170               this              0.017883   \n",
       "10            0.419821               wasn              0.001634   \n",
       "11            0.997004                 't              0.997004   \n",
       "12            0.210132                 it              0.210132   \n",
       "\n",
       "   Negative Log Prob  \n",
       "0           4.978397  \n",
       "1           3.515023  \n",
       "2           3.006014  \n",
       "3           1.195056  \n",
       "4           9.251956  \n",
       "5           3.261401  \n",
       "6           4.676493  \n",
       "7           2.205918  \n",
       "8           2.273497  \n",
       "9           4.023901  \n",
       "10          6.416648  \n",
       "11          0.003001  \n",
       "12          1.560019  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1698d58b-13fe-46d9-9897-ca0fef64b93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(3.5667172307692305)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.to_numeric(df['Negative Log Prob']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62306fd7-a531-4234-bae3-b444b771aa72",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
